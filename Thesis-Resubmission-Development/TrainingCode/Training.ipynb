{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code:\n",
    "\n",
    "## Experiments To Run:\n",
    "\n",
    "### Datasets Comparisons:\n",
    "COCO - Kaggle - Novel\n",
    "\n",
    "### Configurations:\n",
    "\n",
    "#### Epochs:\n",
    "80 - 225 - 300 \n",
    "\n",
    "numbers acquired from papers below:\n",
    "https://www.mdpi.com/1424-8220/22/21/8192/pdf\n",
    "https://www.mdpi.com/2076-3417/11/13/6006/htm\n",
    "\n",
    "#### Batch:\n",
    "8 - 16\n",
    "\n",
    "\n",
    "\n",
    "exp 2 -> 80 epoch 8 batch coco dataset\n",
    "\n",
    "exp 3 -> 225 epoch 16 batch coco dataset -> training stopped at 167 as no change was detected in precision\n",
    "\n",
    "exp 4 -> 80 epoch 16 batch kaggle\n",
    "\n",
    "exp 5 -> 80 epoch 16 batch novel-exp1\n",
    "\n",
    "exp 6 -> 80 epoch 16 batch novel-full\n",
    "\n",
    "exp 7 -> 80 epoch 16 batch novel-full (updated oreos)\n",
    "\n",
    "exp 8 -> 80 epoch 16 batch coco dataset\n",
    "\n",
    "exp 9 -> 80 epoch 16 batch novel-full (further updated oreos)\n",
    "\n",
    "exp 10 -> 80 epoch 16 batch novel-full-augmented\n",
    "\n",
    "exp 11 -> 80 epoch 16 batch novel-exp1-augmented\n",
    "\n",
    "exp 12 -> 80 epoch 16 batch novel-exp1-augmented-2\n",
    "\n",
    "exp 13 -> 80 epoch 16 batch novel-exp1 with yolovx weights\n",
    "\n",
    "exp 14 -> 80 epoch 16 batch  novel-exp1-augmented with yolovx weights\n",
    "\n",
    "exp 15 -> 80 epoch 16 batch coco dataset with yolovx weights (failed)\n",
    "\n",
    "exp 16 -> 80 epoch 16 batch kaggle dataset with yolovx weights\n",
    "\n",
    "exp 17 -> 80 epoch 16 batch novel-augmented with yolovx weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./yolov5-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "directory = 'C:\\\\Users\\\\Natal\\\\Documents\\\\GitHub\\\\Natal-Grima-SWD-63A-Thesis\\\\Thesis-Resubmission-Development\\\\TrainingCode\\\\Datasets\\\\Un-Split-Datasets\\\\Novel-Full-Augmented'\n",
    "\n",
    "if os.path.isdir(os.path.join(directory)):\n",
    "    splitfolders.ratio(directory, output='C:\\\\Users\\\\Natal\\\\Documents\\\\GitHub\\\\Natal-Grima-SWD-63A-Thesis\\\\Thesis-Resubmission-Development\\\\TrainingCode\\\\Datasets\\\\Split-Datasets\\\\Novel-Test', seed=200, ratio=(.7, .3), group_prefix=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING  wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "wandb: Currently logged in as: grimanatal. Use `wandb login --relogin` to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=../Datasets/Novel-Full/NovelFull.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=80, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Natal\\Documents\\GitHub\\Natal-Grima-SWD-63A-Thesis\\Thesis-Resubmission-Development\\TrainingCode\\yolov5-master\\train.py\", line 647, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\Natal\\Documents\\GitHub\\Natal-Grima-SWD-63A-Thesis\\Thesis-Resubmission-Development\\TrainingCode\\yolov5-master\\train.py\", line 511, in main\n",
      "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
      "  File \"c:\\Users\\Natal\\Documents\\GitHub\\Natal-Grima-SWD-63A-Thesis\\Thesis-Resubmission-Development\\TrainingCode\\yolov5-master\\utils\\general.py\", line 458, in check_file\n",
      "    assert len(files), f'File not found: {file}'  # assert file was found\n",
      "AssertionError: File not found: ../Datasets/Novel-Full/NovelFull.yaml\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --batch 16 --epochs 80 --data ../Datasets/Split-Datasets/Novel-Full/NovelFull.yaml --weights yolov5x.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir runs\\train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights ./runs/train/exp9/weights/best.pt --source ../Datasets/Test-Images/Novel-Full/gy.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Code:\n",
    "\n",
    "## Experiments To Run:\n",
    "\n",
    "Here the developed models of the 3 datasets will be tested utilising the detect functionality of yolov5.\n",
    "\n",
    "### Runs:\n",
    "\n",
    "exp 1-4 -> 1.jpg\n",
    "\n",
    "exp 5-8 -> 2.jpg\n",
    "\n",
    "exp 9-12 -> 3.jpg\n",
    "\n",
    "exp 13-16 -> 4.jpg\n",
    "\n",
    "exp 17-20 -> 5.jpg\n",
    "\n",
    "exp 21-24 -> 6.jpg\n",
    "\n",
    "exp 25-28 -> 7.jpg\n",
    "\n",
    "exp 29-32 -> 8.jpg\n",
    "\n",
    "exp 33-36 -> 9.jpg\n",
    "\n",
    "exp 37-40 -> 10.jpg\n",
    "\n",
    "exp 41-44 -> 11.jpg\n",
    "\n",
    "exp 45-48 -> 12.jpg\n",
    "\n",
    "exp 49-52 -> 13.jpg\n",
    "\n",
    "exp 53-56 -> 15.jpg\n",
    "\n",
    "exp 57-60 -> 16.jpg\n",
    "\n",
    "exp 61-64 -> 17.jpg\n",
    "\n",
    "exp 65-68 -> 18.jpg\n",
    "\n",
    "exp 69-72 -> 19.jpg\n",
    "\n",
    "exp 73-76 -> 20.jpg\n",
    "\n",
    "exp 77-80 -> 21.jpg\n",
    "\n",
    "exp 81-84 -> 22.jpg\n",
    "\n",
    "exp 85-88 -> 23.jpg\n",
    "\n",
    "exp 89-92 -> 24.jpg\n",
    "\n",
    "exp 93-96 -> 25.jpg\n",
    "\n",
    "exp 97-100 -> 26.jpg\n",
    "\n",
    "exp 101-104 -> 27.jpg\n",
    "\n",
    "exp 105-108 -> 28.jpg\n",
    "\n",
    "exp 109-112 -> 29.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models:\n",
    "# Coco: exp 8\n",
    "# Kaggle: exp 16\n",
    "# Novel: exp 13\n",
    "# Novel Augmented: exp14\n",
    "\n",
    "# COCO: 80 epoch model as there was insignificant difference between the 2.\n",
    "!python detect.py --weights ./runs/train/exp8/weights/best.pt --source ../Datasets/Testing/Actual-Images/29.jpg\n",
    "# Kaggle:\n",
    "!python detect.py --weights ./runs/train/exp16/weights/best.pt --source ../Datasets/Testing/Actual-Images/29.jpg\n",
    "# Novel:\n",
    "!python detect.py --weights ./runs/train/exp13/weights/best.pt --source ../Datasets/Testing/Actual-Images/29.jpg\n",
    "# Novel Augmented:\n",
    "!python detect.py --weights ./runs/train/exp14/weights/best.pt --source ../Datasets/Testing/Actual-Images/29.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Code:\n",
    "\n",
    "## Experiments To Run:\n",
    "\n",
    "Here the developed models of the Novel-Full datasets will be tested utilising the detect functionality of yolov5.\n",
    "\n",
    "### Runs:\n",
    "\n",
    "exp 127-128 -> 1.png\n",
    "\n",
    "exp 129-130 -> 2.jpg\n",
    "\n",
    "exp 131-132 -> 3.jpg\n",
    "\n",
    "exp 133-134 -> 4.jpg\n",
    "\n",
    "exp 135-136 -> 5.jpg\n",
    "\n",
    "exp 137-138 -> 6.jpg\n",
    "\n",
    "exp 139-140 -> 7.jpg\n",
    "\n",
    "exp 141-142 -> 8.jpg\n",
    "\n",
    "exp 143-144 -> 9.webp\n",
    "\n",
    "exp 145-146 -> 10.jpg\n",
    "\n",
    "exp 147-148 -> 11.webp\n",
    "\n",
    "exp 149-150 -> 12.jpg\n",
    "\n",
    "exp 151-152 -> 13.jpg\n",
    "\n",
    "exp 153-154 -> 14.webp\n",
    "\n",
    "exp 155-156 -> 15.jpg\n",
    "\n",
    "exp 157-158 -> 16.jpg\n",
    "\n",
    "exp 159-160 -> 17.webp\n",
    "\n",
    "exp 161-162 -> 18.jpg\n",
    "\n",
    "exp 163-164 -> 19.jpg\n",
    "\n",
    "exp 165-166 -> 20.jpg\n",
    "\n",
    "exp 167-168 -> 21.webp\n",
    "\n",
    "exp 169-170 -> 22.jpg\n",
    "\n",
    "exp 171-172 -> 23.png\n",
    "\n",
    "exp 173-174 -> 24.webp\n",
    "\n",
    "exp 175-176 -> 25.webp\n",
    "\n",
    "exp 177-178 -> 26.jpg\n",
    "\n",
    "exp 179-180 -> 27.jpg\n",
    "\n",
    "exp 181-182 -> 28.jpg\n",
    "\n",
    "exp 183-184 -> 29.jpg\n",
    "\n",
    "exp 185-186 -> 30.webp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novel:\n",
    "!python detect.py --weights ./runs/train/exp10/weights/best.pt --source ../Datasets/Testing/Novel-Full/30.webp\n",
    "# Novel-Augmented:\n",
    "!python detect.py --weights ./runs/train/exp17/weights/best.pt --source ../Datasets/Testing/Novel-Full/30.webp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"/cassaralvin/train/runs/p6bn9rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    metrics/mAP_0.5:0.95     x/lr1  _step  train/obj_loss  metrics/recall  \\\n",
      "0               0.164185  0.001700      0        0.046203        0.870444   \n",
      "1               0.341638  0.003457      1        0.046930        0.587784   \n",
      "2               0.290413  0.005169      2        0.040057        0.608777   \n",
      "3               0.271428  0.006836      3        0.036589        0.684648   \n",
      "4               0.395018  0.008459      4        0.032799        0.815418   \n",
      "..                   ...       ...    ...             ...             ...   \n",
      "76              0.802304  0.000719     76        0.014039        0.910007   \n",
      "77              0.793930  0.000595     77        0.013829        0.909326   \n",
      "78              0.797514  0.000471     78        0.014359        0.909586   \n",
      "79              0.793970  0.000348     79        0.014754        0.908413   \n",
      "80              0.803500       NaN     80             NaN        0.969653   \n",
      "\n",
      "                                              Mosaics    _timestamp  \\\n",
      "0   {'format': 'jpg', 'count': 3, 'captions': ['tr...  1.693597e+09   \n",
      "1                                                None  1.693597e+09   \n",
      "2                                                None  1.693597e+09   \n",
      "3                                                None  1.693597e+09   \n",
      "4                                                None  1.693597e+09   \n",
      "..                                                ...           ...   \n",
      "76                                               None  1.693601e+09   \n",
      "77                                               None  1.693602e+09   \n",
      "78                                               None  1.693602e+09   \n",
      "79                                               None  1.693602e+09   \n",
      "80                                               None  1.693602e+09   \n",
      "\n",
      "                                               Labels  train/box_loss  \\\n",
      "0   {'format': 'jpg', 'height': 1600, 'width': 160...        0.105678   \n",
      "1                                                None        0.075265   \n",
      "2                                                None        0.069484   \n",
      "3                                                None        0.066634   \n",
      "4                                                None        0.069677   \n",
      "..                                                ...             ...   \n",
      "76                                               None        0.014652   \n",
      "77                                               None        0.015583   \n",
      "78                                               None        0.015879   \n",
      "79                                               None        0.015314   \n",
      "80                                               None             NaN   \n",
      "\n",
      "       x/lr2  val/box_loss  val/cls_loss  \\\n",
      "0   0.001700      0.052982      0.024478   \n",
      "1   0.003457      0.029944      0.016428   \n",
      "2   0.005169      0.036189      0.008421   \n",
      "3   0.006836      0.042192      0.006510   \n",
      "4   0.008459      0.039924      0.004563   \n",
      "..       ...           ...           ...   \n",
      "76  0.000719      0.010917      0.001017   \n",
      "77  0.000595      0.010976      0.001033   \n",
      "78  0.000471      0.010876      0.000993   \n",
      "79  0.000348      0.010854      0.001004   \n",
      "80       NaN      0.011729      0.001059   \n",
      "\n",
      "                                              Results     _runtime  \\\n",
      "0                                                None   219.935436   \n",
      "1                                                None   280.855364   \n",
      "2                                                None   337.863236   \n",
      "3                                                None   397.376197   \n",
      "4                                                None   459.752764   \n",
      "..                                                ...          ...   \n",
      "76                                               None  4755.523850   \n",
      "77                                               None  4845.112883   \n",
      "78                                               None  4936.329557   \n",
      "79                                               None  5021.965509   \n",
      "80  {'_type': 'images/separated', 'format': 'png',...  5030.817772   \n",
      "\n",
      "    metrics/mAP_0.5  val/obj_loss  metrics/precision  \\\n",
      "0          0.348238      0.017722           0.005758   \n",
      "1          0.638675      0.015957           0.459395   \n",
      "2          0.630867      0.009366           0.521236   \n",
      "3          0.598189      0.007247           0.481114   \n",
      "4          0.772322      0.006423           0.657828   \n",
      "..              ...           ...                ...   \n",
      "76         0.941958      0.004974           0.956145   \n",
      "77         0.940955      0.005001           0.958261   \n",
      "78         0.940775      0.005065           0.962233   \n",
      "79         0.940775      0.005052           0.959052   \n",
      "80         0.968186      0.004994           0.905867   \n",
      "\n",
      "                                           Validation     x/lr0  \\\n",
      "0                                                None  0.084700   \n",
      "1                                                None  0.068457   \n",
      "2                                                None  0.052169   \n",
      "3                                                None  0.035836   \n",
      "4                                                None  0.019459   \n",
      "..                                                ...       ...   \n",
      "76                                               None  0.000719   \n",
      "77                                               None  0.000595   \n",
      "78                                               None  0.000471   \n",
      "79                                               None  0.000348   \n",
      "80  {'_type': 'images/separated', 'format': 'jpg',...       NaN   \n",
      "\n",
      "    train/cls_loss  \n",
      "0         0.045085  \n",
      "1         0.036778  \n",
      "2         0.026496  \n",
      "3         0.021268  \n",
      "4         0.013758  \n",
      "..             ...  \n",
      "76        0.000825  \n",
      "77        0.000823  \n",
      "78        0.000679  \n",
      "79        0.000762  \n",
      "80             NaN  \n",
      "\n",
      "[81 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "print(run.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../Datasets/Kaggle/KaggleTraining.yaml, weights=['./runs/train/exp16/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs\\val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5  2023-8-1 Python-3.10.12 torch-2.0.1 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12282MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86193601 parameters, 0 gradients, 203.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Natal\\Documents\\GitHub\\Natal-Grima-SWD-63A-Thesis\\Thesis-Resubmission-Development\\TrainingCode\\Datasets\\Kaggle\\validation\\apple.cache... 37 images, 2 backgrounds, 0 corrupt: 100%|██████████| 37/37 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Natal\\Documents\\GitHub\\Natal-Grima-SWD-63A-Thesis\\Thesis-Resubmission-Development\\TrainingCode\\Datasets\\Kaggle\\validation\\apple.cache... 37 images, 2 backgrounds, 0 corrupt: 100%|██████████| 37/37 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/2 [00:00<?, ?it/s]WARNING  NMS time limit 2.100s exceeded\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 1/2 [00:20<00:20, 20.55s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:26<00:00, 11.81s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 2/2 [00:26<00:00, 13.12s/it]\n",
      "                   all         37         59      0.961      0.164      0.211      0.173\n",
      "                 apple         37         16      0.917       0.25       0.34      0.318\n",
      "                banana         37          9          1          0          0          0\n",
      "                carrot         37         11      0.989      0.364      0.423      0.302\n",
      "                orange         37         23      0.939     0.0435     0.0817     0.0735\n",
      "Speed: 3.9ms pre-process, 504.6ms inference, 105.0ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\val\\exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --data ../Datasets/Kaggle/KaggleTraining.yaml --weights ./runs/train/exp16/weights/best.pt --img-size 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
